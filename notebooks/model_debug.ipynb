{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Santosh-Gupta/NaturalLanguageRecommendations/blob/srihari-dev/notebooks/model_debug.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "QK0_IOe0LkEY",
    "outputId": "a93f7933-9e96-44f3-b3d3-8c9b34ce0729"
   },
   "outputs": [],
   "source": [
    "!pip install transformers --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "S_hHnz5fLiZ5",
    "outputId": "46ff45b2-dbc8-4581-ff79-9d223fde1807"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow: 2.1.0-rc0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Lambda, Dense, Activation, Concatenate\n",
    "from transformers import TFBertModel\n",
    "print('TensorFlow:', tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 748
    },
    "colab_type": "code",
    "id": "-1Mu1rsDMHCF",
    "outputId": "1388d8de-73e0-4c54-f4fc-f1135358cae3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPLICAS:  1\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
    "    print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
    "except ValueError:\n",
    "    tpu = None\n",
    "\n",
    "if tpu:\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "else:\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "\n",
    "print(\"REPLICAS: \", strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "embedding_dim = 512\n",
    "autotune = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iYONEmj6LiZ9"
   },
   "outputs": [],
   "source": [
    "def get_random_title():\n",
    "    return tf.random.uniform(shape=[512], maxval=200, dtype=tf.int32)\n",
    "\n",
    "def get_random_citation():\n",
    "    vector = tf.random.uniform(shape=[embedding_dim], minval=-1, maxval=1, dtype=tf.float32)\n",
    "    normed_vector = tf.math.l2_normalize(vector)\n",
    "    return normed_vector\n",
    "\n",
    "def generate_sample():\n",
    "    title = get_random_title()\n",
    "    posCitations = get_random_citation()\n",
    "    return title, posCitations\n",
    "\n",
    "def create_labels(title, posCitations):\n",
    "    batch_size = tf.shape(title)[0]\n",
    "    return (title, posCitations), tf.eye(batch_size, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TidDJ55-LiZ_"
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    title = tf.keras.Input(shape=(512,), dtype=tf.int32) # from bert encoder\n",
    "    citation = tf.keras.Input(shape=(512,)) # normalized word2vec outputs\n",
    "    \n",
    "    bert_model = TFBertModel.from_pretrained('bert-base-uncased')\n",
    "    titleOut = bert_model(title)\n",
    "    titleOutMean = tf.reduce_mean(titleOut[0], axis=1)\n",
    "    titleOutSim = Dense(units=embedding_dim, activation='tanh', name='DenseTitle')(titleOutMean)\n",
    "\n",
    "    citationSim = Dense(units=embedding_dim, activation='tanh', name='DenseCitation')(citation)\n",
    "\n",
    "    # Get dot product of each of title x citation combinations\n",
    "    dotProduct = tf.reduce_sum(tf.multiply(titleOutSim[:, tf.newaxis, :], citationSim), axis=-1)\n",
    "    \n",
    "    # Softmax across rows to get sum == 1 for each row\n",
    "    probs = tf.nn.softmax(dotProduct, axis=-1)\n",
    "    return tf.keras.Model(inputs=[title, citation], outputs=[probs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o8MXgYFSLiaB"
   },
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    model = create_model()\n",
    "    model.compile(loss=tf.losses.CategoricalCrossentropy(from_logits=False),\n",
    "                optimizer=tf.optimizers.Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "JAMCPvDTLiaD",
    "outputId": "721ce242-6087-4015-aa56-0952eb312478"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((TensorSpec(shape=(None, 512), dtype=tf.int32, name=None), TensorSpec(shape=(None, 512), dtype=tf.float32, name=None)), TensorSpec(shape=(None, None), dtype=tf.float32, name=None))\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    dataset = tf.data.Dataset.range(5000)\n",
    "    dataset = dataset.shuffle(512)\n",
    "    dataset = dataset.map(lambda _ : generate_sample(), num_parallel_calls=autotune)\n",
    "    dataset = dataset.batch(batch_size, drop_remainder=False)\n",
    "    dataset = dataset.map(create_labels, num_parallel_calls=autotune)\n",
    "    dataset = dataset.prefetch(autotune)\n",
    "    print(tf.data.experimental.get_structure(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 833
    },
    "colab_type": "code",
    "id": "p6S3kWXPLiaF",
    "outputId": "43cd5b8d-66eb-458e-b023-ba7aa88b88e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 100 steps\n",
      "Epoch 1/5\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
      "100/100 [==============================] - 49s 494ms/step - loss: 2.5882\n",
      "Epoch 2/5\n",
      "100/100 [==============================] - 41s 411ms/step - loss: 3.1522\n",
      "Epoch 3/5\n",
      "100/100 [==============================] - 42s 422ms/step - loss: 3.2150\n",
      "Epoch 4/5\n",
      "100/100 [==============================] - 42s 424ms/step - loss: 3.4208\n",
      "Epoch 5/5\n",
      "100/100 [==============================] - 42s 424ms/step - loss: 3.7316\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fbd887d0cf8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(dataset, epochs=5, steps_per_epoch=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xSq8y6cbLiaH"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "include_colab_link": true,
   "name": "model_debug.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
