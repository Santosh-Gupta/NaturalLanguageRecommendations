{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Santosh-Gupta/NaturalLanguageRecommendations/blob/srihari-dev/notebooks/model_debug.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "QK0_IOe0LkEY",
    "outputId": "51bec35b-1da5-47c0-c64b-e7d49d87f578"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 19.2.1, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%tensorflow_version` not found.\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers tqdm --quiet\n",
    "%tensorflow_version 2.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "S_hHnz5fLiZ5",
    "outputId": "1ad991c6-f66e-47bf-f9d4-73008b788daf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow: 2.0.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Lambda, Dense, Activation, Concatenate\n",
    "from transformers import TFBertModel\n",
    "print('TensorFlow:', tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 748
    },
    "colab_type": "code",
    "id": "-1Mu1rsDMHCF",
    "outputId": "9f3800ed-4db0-4e7e-f6c9-444d5b656470"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1224 01:37:50.389210 4672177600 cross_device_ops.py:1209] There is non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPLICAS:  1\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
    "    print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
    "except ValueError:\n",
    "    tpu = None\n",
    "\n",
    "if tpu:\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "else:\n",
    "    strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "print(\"REPLICAS: \", strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dYscLlW_7wIR"
   },
   "outputs": [],
   "source": [
    "batch_size = 12 * strategy.num_replicas_in_sync\n",
    "embedding_dim = 512\n",
    "autotune = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_title():\n",
    "    return tf.random.uniform(shape=[512], maxval=200, dtype=tf.int32)\n",
    "\n",
    "def get_random_citation():\n",
    "    vector = tf.random.uniform(shape=[embedding_dim], minval=-1, maxval=1, dtype=tf.float32)\n",
    "    normed_vector = tf.math.l2_normalize(vector)\n",
    "    return normed_vector\n",
    "\n",
    "def generate_sample():\n",
    "    title = get_random_title()\n",
    "    posCitations = get_random_citation()\n",
    "    return title, posCitations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TFrecordWriter:\n",
    "    def __init__(self,\n",
    "                 n_samples,\n",
    "                 n_shards,\n",
    "                 output_dir='',\n",
    "                 prefix=''):\n",
    "        self.n_samples = n_samples\n",
    "        self.n_shards = n_shards\n",
    "        self.step_size = self.n_samples//self.n_shards + 1\n",
    "        self.prefix = prefix\n",
    "        self.output_dir = output_dir\n",
    "        self.buffer = []\n",
    "        self.file_count = 1\n",
    "        \n",
    "    def make_example(self, title, vector):\n",
    "        feature = {\n",
    "            'title': tf.train.Feature(int64_list=tf.train.Int64List(value=title)),\n",
    "            'citation': tf.train.Feature(float_list=tf.train.FloatList(value=vector))\n",
    "        }\n",
    "        return tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "        \n",
    "    def write_tfrecord(self, tfrecord_path):\n",
    "        print('writing {} samples in {}'.format(len(self.buffer), tfrecord_path))\n",
    "        with tf.io.TFRecordWriter(tfrecord_path) as writer:\n",
    "            for (title, vector) in tqdm(self.buffer):\n",
    "                example = self.make_example(title, vector)\n",
    "                writer.write(example.SerializeToString())\n",
    "    \n",
    "    def push(self, title, vector):\n",
    "        self.buffer.append([title, vector])\n",
    "        if len(self.buffer) == self.step_size:\n",
    "            fname = self.prefix + '_000' + str(self.file_count) + '.tfrecord'\n",
    "            tfrecord_path = os.path.join(self.output_dir, fname)\n",
    "            self.write_tfrecord(tfrecord_path)\n",
    "            self.clear_buffer()\n",
    "            self.file_count += 1\n",
    "            \n",
    "    def flush_last(self):\n",
    "        if len(self.buffer):\n",
    "            fname = self.prefix + '_000' + str(self.file_count) + '.tfrecord'\n",
    "            tfrecord_path = os.path.join(self.output_dir, fname)\n",
    "            self.write_tfrecord(tfrecord_path)\n",
    "            \n",
    "    def clear_buffer(self):\n",
    "        self.buffer = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: tfrecords: File exists\n",
      "writing 167 samples in tfrecords/train_0001.tfrecord\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7960d5b4731f4c159c7f9c13ee36de67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=167), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "writing 167 samples in tfrecords/train_0002.tfrecord\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1eb1809b60c547d7b73ca8bd9fa21173",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=167), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "writing 167 samples in tfrecords/train_0003.tfrecord\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9f1915eaade4911b1c8cf920d8c33de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=167), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "writing 167 samples in tfrecords/train_0004.tfrecord\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cd6d1267f8b42ba9c8784e0dfc19e4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=167), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "writing 167 samples in tfrecords/train_0005.tfrecord\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9082cb1c7424236aafe9ac8f089680a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=167), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "writing 165 samples in tfrecords/train_0006.tfrecord\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6eec7d4985b14949a7030109eda6d680",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=165), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "!mkdir 'tfrecords'\n",
    "tfrecord_writer = TFrecordWriter(1000, 6, 'tfrecords', 'train')\n",
    "\n",
    "for i in range(1000):\n",
    "    title, vector = generate_sample()\n",
    "    tfrecord_writer.push(title, vector)\n",
    "tfrecord_writer.flush_last()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = 'tfrecords'\n",
    "tfrecords_pattern = os.path.join(base_dir, 'train*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iYONEmj6LiZ9"
   },
   "outputs": [],
   "source": [
    "features = {\n",
    "    'title':tf.io.FixedLenFeature([512], dtype=tf.int64),\n",
    "    'citation':tf.io.FixedLenFeature([512], dtype=tf.float32),\n",
    "    }\n",
    "\n",
    "def parse_example(example_proto):\n",
    "    parsed_example = tf.io.parse_single_example(example_proto, features)\n",
    "    title = parsed_example['title']\n",
    "    citation = parsed_example['citation']\n",
    "    return (title, citation), 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((TensorSpec(shape=(12, 512), dtype=tf.int64, name=None),\n",
       "  TensorSpec(shape=(12, 512), dtype=tf.float32, name=None)),\n",
       " TensorSpec(shape=(12,), dtype=tf.float32, name=None))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    files = tf.data.Dataset.list_files(tfrecords_pattern)\n",
    "    dataset = files.interleave(tf.data.TFRecordDataset,\n",
    "                               cycle_length=16,\n",
    "                               block_length=4,\n",
    "                               num_parallel_calls=autotune)\n",
    "    dataset = dataset.map(parse_example, num_parallel_calls=autotune)\n",
    "    dataset = dataset.batch(batch_size, drop_remainder=True)\n",
    "    dataset = dataset.prefetch(autotune)\n",
    "tf.data.experimental.get_structure(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TidDJ55-LiZ_"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def loss_fn(_, probs):\n",
    "    '''\n",
    "        1. Every sample is its own positive, and  the rest of the\n",
    "            elements in the batch are its negative.\n",
    "        2. Each TPU core gets 1/8 * global_batch_size elements, hence\n",
    "            compute shape dynamically.\n",
    "        3. Dataset produces dummy labels to make sure the loss_fn matches\n",
    "            the loss signature of keras, actual labels are computed inside this\n",
    "            function.\n",
    "    '''\n",
    "    bs = tf.shape(probs)[0] \n",
    "    labels = tf.eye(bs, bs)\n",
    "    return tf.losses.categorical_crossentropy(labels, probs)\n",
    "    \n",
    "def create_model():\n",
    "    title = tf.keras.Input(shape=(512,), dtype=tf.int32)    # from bert tokenizer\n",
    "    citation = tf.keras.Input(shape=(512,))                 # normalized word2vec outputs\n",
    "    \n",
    "    bert_model = TFBertModel.from_pretrained('bert-base-uncased')\n",
    "    \n",
    "    titleOut = bert_model(title)\n",
    "    titleOutMean = tf.reduce_mean(titleOut[0], axis=1)\n",
    "    titleOutSim = Dense(units=embedding_dim, activation='tanh', name='DenseTitle')(titleOutMean)\n",
    "\n",
    "    citationSim = Dense(units=embedding_dim, activation='tanh', name='DenseCitation')(citation)\n",
    "\n",
    "    # Get dot product of each of title x citation combinations\n",
    "    dotProduct = tf.reduce_sum(tf.multiply(titleOutSim[:, None, :], citationSim), axis=-1)\n",
    "    \n",
    "    # Softmax to make sure each row has sum == 1.0\n",
    "    probs = tf.nn.softmax(dotProduct, axis=-1)\n",
    "\n",
    "    model = tf.keras.Model(inputs=[title, citation], outputs=[probs])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o8MXgYFSLiaB"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1224 01:53:04.251464 4672177600 modeling_tf_utils.py:339] Layers from pretrained model not used in TFBertModel: ['mlm___cls', 'nsp___cls']\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    model = create_model()\n",
    "    model.compile(loss=loss_fn, optimizer=tf.optimizers.Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_bert_model (TFBertModel)     ((None, 512, 768), ( 109482240   input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mean (TensorFlowOpL [(None, 768)]        0           tf_bert_model[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "DenseTitle (Dense)              (None, 512)          393728      tf_op_layer_Mean[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice (Tens [(None, 1, 512)]     0           DenseTitle[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "DenseCitation (Dense)           (None, 512)          262656      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul (TensorFlowOpLa [(None, None, 512)]  0           tf_op_layer_strided_slice[0][0]  \n",
      "                                                                 DenseCitation[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sum (TensorFlowOpLa [(None, None)]       0           tf_op_layer_Mul[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Softmax (TensorFlow [(None, None)]       0           tf_op_layer_Sum[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 110,138,624\n",
      "Trainable params: 110,138,624\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "p6S3kWXPLiaF",
    "outputId": "8550ec09-70fc-4ace-b456-7a83b3234fbe"
   },
   "outputs": [],
   "source": [
    "model.fit(dataset, epochs=5, steps_per_epoch=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "include_colab_link": true,
   "name": "model_debug.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
